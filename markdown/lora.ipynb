{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3011722a-7488-416f-9033-ff53758ab3fb",
   "metadata": {},
   "source": [
    "# lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f0a3b-2989-4442-8847-b3201841b49c",
   "metadata": {},
   "source": [
    " - [大模型高效微调-LoRA原理详解和训练过程深入分析](https://www.cnblogs.com/justLittleStar/p/18242820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8d802c-4a27-4491-9219-90868bbb7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "lora_rank = 2\n",
    "model_dim = 16\n",
    "\n",
    "class Lora(nn.Module):\n",
    "    def __init__(self, lora_rank, model_dim):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.randn(model_dim, lora_rank) / torch.sqrt(torch.tensor(lora_rank)), requires_grad=True)\n",
    "        self.B = nn.Parameter(torch.zeros(lora_rank, model_dim) / torch.sqrt(torch.tensor(lora_rank)), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        return x @ self.A @ self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1eeed41-8d35-4fb3-8174-6a72e660f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora = Lora(lora_rank, model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354916aa-465a-4410-9961-385bdc25ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params=lora.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68311903-159f-41a6-83bd-63181f8dc687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "step0 norm(lora.A.grad): tensor(0.)\n",
      "step0 norm(lora.B.grad): tensor(0.7942)\n",
      "step0 norm(y): tensor(0., grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step1 norm(lora.A.grad): tensor(0.0096)\n",
      "step1 norm(lora.B.grad): tensor(0.6021)\n",
      "step1 norm(y): tensor(0.0174, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step2 norm(lora.A.grad): tensor(0.0129)\n",
      "step2 norm(lora.B.grad): tensor(0.0650)\n",
      "step2 norm(y): tensor(0.0054, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step3 norm(lora.A.grad): tensor(0.0273)\n",
      "step3 norm(lora.B.grad): tensor(0.5162)\n",
      "step3 norm(y): tensor(0.0678, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step4 norm(lora.A.grad): tensor(0.0482)\n",
      "step4 norm(lora.B.grad): tensor(0.5253)\n",
      "step4 norm(y): tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step5 norm(lora.A.grad): tensor(0.0520)\n",
      "step5 norm(lora.B.grad): tensor(0.3292)\n",
      "step5 norm(y): tensor(0.0604, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step6 norm(lora.A.grad): tensor(0.0404)\n",
      "step6 norm(lora.B.grad): tensor(0.6493)\n",
      "step6 norm(y): tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step7 norm(lora.A.grad): tensor(0.0635)\n",
      "step7 norm(lora.B.grad): tensor(0.2695)\n",
      "step7 norm(y): tensor(0.0119, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step8 norm(lora.A.grad): tensor(0.0704)\n",
      "step8 norm(lora.B.grad): tensor(0.7835)\n",
      "step8 norm(y): tensor(0.0632, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.0781)\n",
      "step9 norm(lora.B.grad): tensor(0.1831)\n",
      "step9 norm(y): tensor(0.0485, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print('-' * 100)\n",
    "    optimizer.zero_grad()\n",
    "    x = torch.randn((model_dim, ))\n",
    "    y = lora(x)\n",
    "    z = y.mean()\n",
    "    z.backward()\n",
    "    print(f'step{idx} norm(lora.A.grad):', torch.norm(lora.A.grad))\n",
    "    print(f'step{idx} norm(lora.B.grad):', torch.norm(lora.B.grad))\n",
    "    print(f'step{idx} norm(y):', torch.norm(y))\n",
    "    # print('lora.A:', lora.A)\n",
    "    # print('lora.B:', lora.B)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1baf76ea-5119-47b5-a696-e5656034d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lora2(nn.Module):\n",
    "    def __init__(self, lora_rank, model_dim):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.zeros(model_dim, lora_rank) / torch.sqrt(torch.tensor(lora_rank)), requires_grad=True)\n",
    "        self.B = nn.Parameter(torch.randn(lora_rank, model_dim) / torch.sqrt(torch.tensor(lora_rank)), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        return x @ self.A @ self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad82a62-9759-4764-825f-1e79769885d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora = Lora2(lora_rank, model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0da87d-2342-4f05-9069-1ca8ee7b8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params=lora.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d080afe-da0a-414b-81b4-049ed95f9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.6384)\n",
      "step9 norm(lora.B.grad): tensor(0.)\n",
      "step9 norm(y): tensor(0., grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.6017)\n",
      "step9 norm(lora.B.grad): tensor(0.0074)\n",
      "step9 norm(y): tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.6816)\n",
      "step9 norm(lora.B.grad): tensor(0.0046)\n",
      "step9 norm(y): tensor(0.0440, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.7764)\n",
      "step9 norm(lora.B.grad): tensor(0.0587)\n",
      "step9 norm(y): tensor(0.5567, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.6314)\n",
      "step9 norm(lora.B.grad): tensor(0.0996)\n",
      "step9 norm(y): tensor(0.9460, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.9816)\n",
      "step9 norm(lora.B.grad): tensor(0.1208)\n",
      "step9 norm(y): tensor(1.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.9332)\n",
      "step9 norm(lora.B.grad): tensor(0.0459)\n",
      "step9 norm(y): tensor(0.4362, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.6844)\n",
      "step9 norm(lora.B.grad): tensor(0.1665)\n",
      "step9 norm(y): tensor(1.5840, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(0.7219)\n",
      "step9 norm(lora.B.grad): tensor(0.0180)\n",
      "step9 norm(y): tensor(0.1716, grad_fn=<LinalgVectorNormBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "step9 norm(lora.A.grad): tensor(1.1452)\n",
      "step9 norm(lora.B.grad): tensor(0.1191)\n",
      "step9 norm(y): tensor(1.1414, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print('-' * 100)\n",
    "    optimizer.zero_grad()\n",
    "    x = torch.randn((model_dim, ))\n",
    "    y = lora(x)\n",
    "    z = y.mean()\n",
    "    z.backward()\n",
    "    print(f'step{idx} norm(lora.A.grad):', torch.norm(lora.A.grad))\n",
    "    print(f'step{idx} norm(lora.B.grad):', torch.norm(lora.B.grad))\n",
    "    print(f'step{idx} norm(y):', torch.norm(y))\n",
    "    # print('lora.A:', lora.A)\n",
    "    # print('lora.B:', lora.B)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72801a-fb1a-487f-8a60-0d5ee706125f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518e5ee-06ee-493b-94f9-54725803d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
